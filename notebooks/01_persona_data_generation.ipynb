{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Persona Data Generation\n",
    "\n",
    "Generate contrastive response pairs for each persona using the Deep Infra API.\n",
    "\n",
    "For each persona Ã— each evaluation prompt, we generate:\n",
    "- A **trait response** (system prompt exhibiting the persona)\n",
    "- An **anti-trait response** (system prompt exhibiting the opposite)\n",
    "\n",
    "These contrastive pairs are what we'll feed through GPT-2 medium in Notebook 2 to extract persona vectors.\n",
    "\n",
    "Progress saves incrementally to `data/persona_responses.json` so you can stop and resume without re-spending on API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.personas import PERSONAS, EVALUATION_PROMPTS\n",
    "from src.api_client import get_client, generate_contrastive_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect personas and prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personas: 9\n",
      "Number of evaluation prompts: 40\n",
      "Total API calls needed: 720\n",
      "\n",
      "  - Urgent & Direct: Agent who cuts to the chase â€” apologizes fast, leads with the fix, no fluff.\n",
      "  - Warm & Patient: Agent who takes their time, explains step by step, makes you feel welcome.\n",
      "  - Polished & Premium: Agent with a white-glove tone â€” proactive, personalized, goes above and beyond.\n",
      "  - Technical & Precise: Agent who gives detailed, specific answers with exact steps and specs.\n",
      "  - Empathetic & Compassionate: Agent who leads with feelings â€” acknowledges emotions before solving problems.\n",
      "  - Friendly & Conversational: Agent who chats naturally â€” personable, uses humor, builds rapport.\n",
      "  - Value-Focused: Agent who proactively surfaces deals, savings, and cost-effective options.\n",
      "  - Gentle & Simple: Agent who uses very simple language, short sentences, and a kind tone â€” like a teacher.\n",
      "  - Cautious & Thorough: Agent who covers all the caveats, edge cases, and fine print upfront.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of personas: {len(PERSONAS)}\")\n",
    "print(f\"Number of evaluation prompts: {len(EVALUATION_PROMPTS)}\")\n",
    "print(f\"Total API calls needed: {len(PERSONAS) * len(EVALUATION_PROMPTS) * 2}\")\n",
    "print()\n",
    "for p in PERSONAS:\n",
    "    print(f\"  - {p['label']}: {p['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a single persona + prompt pair\n",
    "\n",
    "Before running the full batch, let's verify the API works and see what a contrastive pair looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: Urgent & Direct\n",
      "Prompt: My order hasn't arrived and it's been two weeks. What's going on?\n",
      "\n",
      "=== TRAIT RESPONSE ===\n",
      "Sorry for the delay. Send me your order number. Iâ€™ll locate the shipment, confirm its status, and either expedite delivery or issue a refund. Let me know which you prefer.\n",
      "\n",
      "=== ANTI-TRAIT RESPONSE ===\n",
      "Hello there! ðŸŒŸ First of all, thank you ever so much for reaching out and taking the time to let us know about the situation with your order. I truly appreciate your patience and understand how frustrating it can be when something youâ€™re looking forward to doesnâ€™t arrive on schedule. Itâ€™s completely normal to feel a little uneasy when a delivery takes longer than expected, especially when youâ€™ve been waiting for a couple of weeks now. \n",
      "\n",
      "Let me start by saying how sorry we are for any inconvenience this has caused you. We strive to make every experience as smooth and delightful as possible, and when we fall short of that, itâ€™s important to us to understand why and to make things right. \n",
      "\n",
      "### Why might an order take longer than anticipated?\n",
      "\n",
      "There are several moving parts that come into play once an order leaves our warehouse, and sometimes a few of those parts can encounter unexpected hiccups. Here are a few of the most common reasons why an order might be delayed:\n",
      "\n",
      "1. **Carrier Transit Delays** â€“ Once the package is handed over to the shipping carrier (such as UPS, FedEx, DHL, or a local postal service), they handle the logistics of getting it to you. Occasionally, they experience high volumes (especially around holidays or sales events), weather disruptions, or routing issues that can add extra days to the transit time.\n",
      "\n",
      "2. **Customs and International Processing** â€“ If your order is traveling across borders, customs clearance can sometimes take longer than usual. This is out of our direct control, but we do try to provide all the necessary documentation to keep the process as swift as possible.\n",
      "\n",
      "3. **Address Verification Issues** â€“ Occasionally, if thereâ€™s a small discrepancy or missing information in the shipping address, the carrier may need to pause delivery to verify details. This can add a day or two, and sometimes it can cause a longer hold while they attempt contact.\n",
      "\n",
      "4. **Internal Handling Glitches** â€“ While rare, sometimes our own fulfillment center may experience a backlog, a mislabel, or a temporary system hiccup that can\n"
     ]
    }
   ],
   "source": [
    "from src.api_client import generate_response\n",
    "\n",
    "client = get_client()\n",
    "\n",
    "test_persona = PERSONAS[0]  # Frustrated Customer\n",
    "test_prompt = EVALUATION_PROMPTS[0]\n",
    "\n",
    "print(f\"Persona: {test_persona['label']}\")\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print()\n",
    "\n",
    "trait_resp = generate_response(client, test_persona['system_prompt'], test_prompt)\n",
    "print(\"=== TRAIT RESPONSE ===\")\n",
    "print(trait_resp)\n",
    "print()\n",
    "\n",
    "anti_resp = generate_response(client, test_persona['anti_system_prompt'], test_prompt)\n",
    "print(\"=== ANTI-TRAIT RESPONSE ===\")\n",
    "print(anti_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate all contrastive pairs\n",
    "\n",
    "This will take a while. Progress is saved after every pair, so it's safe to interrupt and resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/360\n",
      "Progress: 20/360\n",
      "Progress: 30/360\n",
      "Progress: 40/360\n",
      "Progress: 50/360\n",
      "Progress: 60/360\n",
      "Progress: 70/360\n",
      "Progress: 80/360\n",
      "Progress: 90/360\n",
      "Progress: 100/360\n",
      "Progress: 110/360\n",
      "Progress: 120/360\n",
      "Progress: 130/360\n",
      "Progress: 140/360\n",
      "Progress: 150/360\n",
      "Progress: 160/360\n",
      "Progress: 170/360\n",
      "Progress: 180/360\n",
      "Progress: 190/360\n",
      "Progress: 200/360\n",
      "Progress: 210/360\n",
      "Progress: 220/360\n",
      "Progress: 230/360\n",
      "Progress: 240/360\n",
      "Progress: 250/360\n",
      "Progress: 260/360\n",
      "Progress: 270/360\n",
      "Progress: 280/360\n",
      "Progress: 290/360\n",
      "Progress: 300/360\n",
      "Progress: 310/360\n",
      "Progress: 320/360\n",
      "Progress: 330/360\n",
      "Progress: 340/360\n",
      "Progress: 350/360\n",
      "Progress: 360/360\n",
      "Done! 360/360 pairs saved to ../data/persona_responses.json\n"
     ]
    }
   ],
   "source": [
    "client = get_client()\n",
    "\n",
    "results = generate_contrastive_pairs(\n",
    "    client=client,\n",
    "    personas=PERSONAS,\n",
    "    prompts=EVALUATION_PROMPTS,\n",
    "    save_path=\"../data/persona_responses.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas saved: ['urgent_direct', 'warm_patient', 'polished_premium', 'technical_precise', 'empathetic_compassionate', 'friendly_conversational', 'value_focused', 'gentle_simple', 'cautious_thorough']\n",
      "  urgent_direct: 40 prompt pairs\n",
      "  warm_patient: 40 prompt pairs\n",
      "  polished_premium: 40 prompt pairs\n",
      "  technical_precise: 40 prompt pairs\n",
      "  empathetic_compassionate: 40 prompt pairs\n",
      "  friendly_conversational: 40 prompt pairs\n",
      "  value_focused: 40 prompt pairs\n",
      "  gentle_simple: 40 prompt pairs\n",
      "  cautious_thorough: 40 prompt pairs\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/persona_responses.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Personas saved: {list(data.keys())}\")\n",
    "for name, prompts in data.items():\n",
    "    print(f\"  {name}: {len(prompts)} prompt pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: cautious_thorough\n",
      "Prompt: I'm dealing with a family emergency and need to expedite a return.\n",
      "\n",
      "=== TRAIT ===\n",
      "Iâ€™m very sorry to hear that youâ€™re dealing with a family emergency.â€¯Iâ€™ll do my best to walk you through the return process and let you know where we can potentially speed things up, while also outlining the limits of what we can guarantee.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Gather the essential information first  \n",
      "In order to even consider an expedited handling of your return, weâ€™ll need the following details:\n",
      "\n",
      "| What we need | Why it matters |\n",
      "|--------------|----------------|\n",
      "| **Order number** (or receipt/email co\n",
      "\n",
      "=== ANTI-TRAIT ===\n",
      "Iâ€™m so sorry to hear youâ€™re dealing with a family emergencyâ€”letâ€™s get this return taken care of right away so you can focus on what matters most.\n",
      "\n",
      "Hereâ€™s what weâ€™ll do to fastâ€‘track the process:\n",
      "\n",
      "1. **Send me your order number**\n"
     ]
    }
   ],
   "source": [
    "# Look at a random sample\n",
    "import random\n",
    "\n",
    "persona = random.choice(list(data.keys()))\n",
    "prompt_key = random.choice(list(data[persona].keys()))\n",
    "sample = data[persona][prompt_key]\n",
    "\n",
    "print(f\"Persona: {persona}\")\n",
    "print(f\"Prompt: {sample['prompt']}\")\n",
    "print()\n",
    "print(\"=== TRAIT ===\")\n",
    "print(sample['trait_response'][:500])\n",
    "print()\n",
    "print(\"=== ANTI-TRAIT ===\")\n",
    "print(sample['anti_response'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
